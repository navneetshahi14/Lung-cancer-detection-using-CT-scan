{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd36f3-fedc-4c86-8a72-665c6c4ebe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navne\\anaconda3\\envs\\lung_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from utils.dataloader import get_dataloaders\n",
    "from utils.train import train_model, test_model\n",
    "\n",
    "from utils.metrics import (\n",
    "    compute_full_metrics,\n",
    "    save_results_csv,\n",
    "    plot_confusion_matrix,\n",
    "    plot_roc_auc,\n",
    "    save_grayscale_samples,\n",
    "    save_epoch_history_excel\n",
    ")\n",
    "\n",
    "from models.single_models import get_single_model\n",
    "from utils.gradcam import GradCAM, save_gradcam_samples\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de618156-07b7-4690-b0c2-804705fa642c",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82216a03-787c-4fbe-96e3-a27a0a8bf974",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"lung_ct_split\"\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "EPOCH_OPTIONS = [20,25,30]\n",
    "\n",
    "MODELS = [\n",
    "    \"resnet50\",\n",
    "    # \"vgg16\",\n",
    "    # \"densenet121\",\n",
    "    # \"b4\",\n",
    "    # \"efficientnet\",\n",
    "    # \"inception\",\n",
    "    # \"vit\",\n",
    "]\n",
    "\n",
    "PREPROCESSING_CONFIGS = {\n",
    "    \"baseline\": {},\n",
    "    # \"clahe\": {\"clahe\": True},\n",
    "    # \"clahe_median\": {\"clahe\": True, \"median\": True},\n",
    "}\n",
    "\n",
    "\n",
    "CSV_PATH = \"results/reports/final_results.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4893ad27-9594-43c8-8379-22f87cda6fd1",
   "metadata": {},
   "source": [
    "# Ensure Folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "491c3c8d-22e5-455a-ade6-706a69dde493",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results/roc_auc\", exist_ok=True)\n",
    "os.makedirs(\"results/confusion\", exist_ok=True)\n",
    "os.makedirs(\"results/grayscale\", exist_ok=True)\n",
    "os.makedirs(\"saved_models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b77a0b-6b8a-4f65-8ab7-48f93813bc88",
   "metadata": {},
   "source": [
    "# Experiment Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e5080-25bd-4fa9-b86c-d81ef2e8368b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üöÄ RUNNING EXPERIMENT: resnet50_baseline_ep5\n",
      "\n",
      "Epoch 1/5\n",
      "Train Loss: 0.8330 | Train Acc: 0.6128\n",
      "Val   Loss: 0.7443 | Val   Acc: 0.7988\n",
      "\n",
      "Epoch 2/5\n",
      "Train Loss: 0.5338 | Train Acc: 0.7966\n",
      "Val   Loss: 0.4856 | Val   Acc: 0.8110\n",
      "\n",
      "Epoch 3/5\n",
      "Train Loss: 0.3896 | Train Acc: 0.8579\n",
      "Val   Loss: 0.3511 | Val   Acc: 0.8720\n"
     ]
    }
   ],
   "source": [
    "for epochs in EPOCH_OPTIONS:\n",
    "    for model_name in MODELS:\n",
    "        for prep_name, preprocess_cfg in PREPROCESSING_CONFIGS.items():\n",
    "\n",
    "            exp_id = f\"{model_name}_{prep_name}_ep{epochs}\"\n",
    "            print(f\"\\n\\nüöÄ RUNNING EXPERIMENT: {exp_id}\")\n",
    "\n",
    "            train_loader, val_loader, test_loader, class_names = get_dataloaders(\n",
    "                data_dir=DATA_DIR,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                preprocess_config=preprocess_cfg,\n",
    "            )\n",
    "\n",
    "            model = get_single_model(model_name, num_classes=len(class_names)).to(DEVICE)\n",
    "\n",
    "            model, history = train_model(\n",
    "                model,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                DEVICE,\n",
    "                epochs=epochs,\n",
    "                model_name=exp_id,\n",
    "            )\n",
    "\n",
    "            save_epoch_history_excel(history, model_name=preprocess_cfg,save_path=f\"results/{exp_id}/expriment_logs.xlsx\")\n",
    "\n",
    "            test_acc, report, cm, labels, preds, probs, images = test_model(\n",
    "                model,\n",
    "                test_loader,\n",
    "                DEVICE,\n",
    "                class_names,\n",
    "                return_details=True,\n",
    "            )\n",
    "\n",
    "            print(f\"\\nüî• Test Accuracy: {test_acc:.4f}\")\n",
    "            print(report)\n",
    "\n",
    "            accuracy, precision, recall, f1 = compute_full_metrics(labels, preds)\n",
    "\n",
    "            roc_path = f\"results/roc_auc/{exp_id}.png\"\n",
    "            auc_score = plot_roc_auc(labels, probs, class_names, roc_path)\n",
    "\n",
    "            cm_path = f\"results/confusion/{exp_id}.png\"\n",
    "            plot_confusion_matrix(cm, class_names, cm_path)\n",
    "\n",
    "            gray_dir = f\"results/grayscale/{exp_id}\"\n",
    "            save_grayscale_samples(images, gray_dir)\n",
    "\n",
    "            target_layer = None\n",
    "\n",
    "            try:\n",
    "                backbone = model[0]  # because model is Sequential(backbone, classifier)\n",
    "            except:\n",
    "                backbone = model     # for VGG direct return case\n",
    "            \n",
    "            if \"resnet\" in model_name:\n",
    "                target_layer = backbone.layer4[-1]\n",
    "            \n",
    "            elif \"efficientnet\" in model_name:\n",
    "                target_layer = backbone.features[-1]\n",
    "            \n",
    "            elif \"densenet\" in model_name:\n",
    "                target_layer = backbone.features[-1]\n",
    "            \n",
    "            elif \"vgg\" in model_name:\n",
    "                target_layer = backbone.features[-1]\n",
    "            else:\n",
    "                target_layer = None\n",
    "\n",
    "            if target_layer is not None:\n",
    "                gradcam = GradCAM(model, target_layer)\n",
    "                \n",
    "                save_gradcam_samples(\n",
    "                    gradcam,\n",
    "                    images,\n",
    "                    class_names,\n",
    "                    save_dir=f\"results/gradcam/{exp_id}\",\n",
    "                    device=DEVICE,\n",
    "                )\n",
    "\n",
    "            save_results_csv(\n",
    "                {exp_id: accuracy},\n",
    "                CSV_PATH,\n",
    "                preprocess_cfg=preprocess_cfg,\n",
    "                epochs=epochs,\n",
    "                precision=precision,\n",
    "                recall=recall,\n",
    "                f1=f1,\n",
    "                auc_score=auc_score,\n",
    "            )\n",
    "\n",
    "            del model\n",
    "            del train_loader, val_loader, test_loader\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "print(\"\\n\\nüèÅ ALL EXPERIMENTS COMPLETED SUCCESSFULLY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed012d8f-0f7d-4f4b-a8e0-e9d1ebdf69df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lung_gpu)",
   "language": "python",
   "name": "lung_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
