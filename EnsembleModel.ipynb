{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c63a758-7aa1-4e23-bd42-ee0f23bd2533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navne\\anaconda3\\envs\\lung_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from utils.dataloader import get_dataloaders\n",
    "from utils.train import train_model, test_model\n",
    "from utils.metrics import (\n",
    "    compute_full_metrics,\n",
    "    plot_confusion_matrix,\n",
    "    plot_roc_auc,\n",
    "    save_epoch_history_excel,\n",
    "    save_training_summary_excel,\n",
    ")\n",
    "from utils.gradcam import save_gradcam_samples\n",
    "from utils.load_model import load_trained_model\n",
    "\n",
    "from models.single_models import get_single_model\n",
    "from models.ensemble import SoftVotingEnsemble, WeightedEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4a3cb6-038e-438e-9e0a-2f944ec8ed8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"lung_ct_split\"  # change if needed\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 20\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46df8d32-5afb-4a35-b572-8d883a99e31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  ['Bengin cases', 'Malignant cases', 'Normal cases']\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, class_names = get_dataloaders(\n",
    "    data_dir=DATA_DIR,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes: \",class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d155924-be9a-4100-a0a5-0f6349affa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_models = {\n",
    "    \"resnet50\": lambda: get_single_model(\"resnet50\", num_classes),\n",
    "    \"efficientnet_b0\": lambda: get_single_model(\"efficientnet_b0\", num_classes),\n",
    "    \"vgg16\": lambda: get_single_model(\"vgg16\", num_classes),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "histories = {}\n",
    "trained_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f598a9-e9ee-431a-a7a4-8d85c0e1d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, builder in single_models.items():\n",
    "    print(f\"\\n===== TRAINING {name.upper()} =====\")\n",
    "\n",
    "    model = builder().to(DEVICE)\n",
    "\n",
    "    # -------- TRAIN --------\n",
    "    model, history, summary = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        DEVICE,\n",
    "        epochs=EPOCHS,\n",
    "        model_name=name,\n",
    "    )\n",
    "\n",
    "    # -------- LOAD BEST MODEL --------\n",
    "    model = load_trained_model(\n",
    "        builder().to(DEVICE),\n",
    "        f\"results/checkpoints/{name}_best.pth\",\n",
    "        DEVICE,\n",
    "    )\n",
    "\n",
    "    # -------- TEST --------\n",
    "    test_acc, report, cm, labels, preds, probs, images = test_model(\n",
    "        model,\n",
    "        test_loader,\n",
    "        DEVICE,\n",
    "        class_names,\n",
    "        return_details=True,\n",
    "    )\n",
    "\n",
    "    accuracy, precision, recall, f1 = compute_full_metrics(labels, preds)\n",
    "\n",
    "    print(f\"\\n{name} Test Accuracy: {accuracy:.4f}\")\n",
    "    print(report)\n",
    "\n",
    "    # -------- SAVE METRICS --------\n",
    "    results[name] = accuracy\n",
    "    histories[name] = history\n",
    "    trained_models[name] = model\n",
    "\n",
    "    # -------- PLOTS --------\n",
    "    plot_confusion_matrix(cm, class_names)\n",
    "\n",
    "    plot_roc_auc(\n",
    "        labels,\n",
    "        probs,\n",
    "        class_names,\n",
    "        save_path=f\"results/roc_auc/{name}.png\",\n",
    "    )\n",
    "\n",
    "    # -------- SAVE LOGS --------\n",
    "    save_epoch_history_excel(history, model_name=name)\n",
    "    save_training_summary_excel(summary, model_name=name)\n",
    "\n",
    "    # -------- GRAD-CAM --------\n",
    "    save_gradcam_samples(\n",
    "        model,\n",
    "        images,\n",
    "        class_names,\n",
    "        save_dir=f\"results/gradcam/{name}\",\n",
    "        device=DEVICE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9513a8-4733-42b5-9b9f-940e630f076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n===== SOFT VOTING ENSEMBLE =====\")\n",
    "\n",
    "soft_ensemble = SoftVotingEnsemble(list(trained_models.values())).to(DEVICE)\n",
    "\n",
    "acc, report, cm, labels, preds, probs, images = test_model(\n",
    "    soft_ensemble,\n",
    "    test_loader,\n",
    "    DEVICE,\n",
    "    class_names,\n",
    "    return_details=True,\n",
    ")\n",
    "\n",
    "accuracy, precision, recall, f1 = compute_full_metrics(labels, preds)\n",
    "\n",
    "print(f\"Soft Ensemble Accuracy: {accuracy:.4f}\")\n",
    "print(report)\n",
    "\n",
    "plot_confusion_matrix(cm, class_names)\n",
    "plot_roc_auc(labels, probs, class_names, save_path=\"results/roc_auc/soft_ensemble.png\")\n",
    "\n",
    "save_gradcam_samples(\n",
    "    list(trained_models.values())[0],  # use best single model for Grad-CAM\n",
    "    images,\n",
    "    class_names,\n",
    "    save_dir=\"results/gradcam/soft_ensemble\",\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "results[\"soft_ensemble\"] = accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03ff75-987c-47cb-8695-0cd485fba990",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== WEIGHTED ENSEMBLE =====\")\n",
    "\n",
    "# weights based on validation accuracy stored in results\n",
    "weights = [results[m] for m in trained_models.keys()]\n",
    "\n",
    "weighted_ensemble = WeightedEnsemble(\n",
    "    list(trained_models.values()),\n",
    "    weights,\n",
    ").to(DEVICE)\n",
    "\n",
    "acc, report, cm, labels, preds, probs, images = test_model(\n",
    "    weighted_ensemble,\n",
    "    test_loader,\n",
    "    DEVICE,\n",
    "    class_names,\n",
    "    return_details=True,\n",
    ")\n",
    "\n",
    "accuracy, precision, recall, f1 = compute_full_metrics(labels, preds)\n",
    "\n",
    "print(f\"Weighted Ensemble Accuracy: {accuracy:.4f}\")\n",
    "print(report)\n",
    "\n",
    "plot_confusion_matrix(cm, class_names)\n",
    "plot_roc_auc(labels, probs, class_names, save_path=\"results/roc_auc/weighted_ensemble.png\")\n",
    "\n",
    "save_gradcam_samples(\n",
    "    list(trained_models.values())[0],\n",
    "    images,\n",
    "    class_names,\n",
    "    save_dir=\"results/gradcam/weighted_ensemble\",\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "results[\"weighted_ensemble\"] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3cd27-6b7a-4c76-92a3-3fd9a07e9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== FINAL RESULTS =====\")\n",
    "\n",
    "for k, v in results.items():\n",
    "    print(f\"{k:20s} : {v:.4f}\")\n",
    "\n",
    "print(\"\\nPipeline Complete âœ”\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lung_gpu)",
   "language": "python",
   "name": "lung_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
